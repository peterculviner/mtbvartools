{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c92979-fe0a-4521-96a9-38010060c325",
   "metadata": {},
   "source": [
    "# Tree Building Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da6985-b178-4c3c-ae11-442af6e80dc8",
   "metadata": {},
   "source": [
    "Below scripts run through tree building on 61 Mtb isolates downloaded from the SRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b90ceb5-ee0d-45e3-9423-8a0748e03600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, subprocess, dendropy\n",
    "import pandas as pd\n",
    "from Bio import Entrez, SeqIO\n",
    "import mtbvartools as vt\n",
    "from mtbvartools.dasktools import startClient\n",
    "from tqdm import tqdm\n",
    "\n",
    "# add scripts folder to path\n",
    "scripts_path = os.path.abspath('../scripts/')\n",
    "\n",
    "# prepare environment path for subprocesses\n",
    "conda_path = os.path.dirname(sys.executable)  # store conda path for shell execution\n",
    "env = os.environ.copy()\n",
    "env['PATH'] = conda_path + os.pathsep + env['PATH'] + os.pathsep + scripts_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654da09b-e7c0-4214-913f-ea79c579cc9d",
   "metadata": {},
   "source": [
    "## Prepare for Variant Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b16a119-0ce2-43c7-bcfb-52e3e6f4caa8",
   "metadata": {},
   "source": [
    "Download H37Rv v3 genome from the NCBI and prepare indexes used by BWA and GATK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e72c66-2020-417b-86c7-97b102637d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "accession = 'NC_000962.3'  # H37Rv v3 accession number\n",
    "os.makedirs('genome', exist_ok=True)\n",
    "\n",
    "with Entrez.efetch(db='nuccore', rettype='gbwithparts', retmode='text', id=accession) as handle, open(f'genome/{accession}.gb', 'w') as f:\n",
    "    f.write(handle.read())\n",
    "with Entrez.efetch(db='nuccore', rettype='fasta', retmode='text', id=accession) as handle, open(f'genome/{accession}.fasta', 'w') as f:\n",
    "    f.write(handle.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b97252e-9256-4779-99f2-cc85a1b87f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.05 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 1.27 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.04 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.04 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.55 sec\n",
      "[main] Version: 0.7.18-r1243-dirty\n",
      "[main] CMD: bwa index genome/NC_000962.3.fasta\n",
      "[main] Real time: 2.438 sec; CPU: 1.959 sec\n",
      "Using GATK jar /n/home12/pculviner/.conda/envs/mtbvartools/share/gatk4-4.6.1.0-0/gatk-package-4.6.1.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /n/home12/pculviner/.conda/envs/mtbvartools/share/gatk4-4.6.1.0-0/gatk-package-4.6.1.0-local.jar CreateSequenceDictionary -R genome/NC_000962.3.fasta\n",
      "INFO\t2025-03-02 16:00:09\tCreateSequenceDictionary\tOutput dictionary will be written in /n/boslfs02/LABS/sfortune_lab/Lab/culviner/notebooks/250301_prepare_uploads/mtbvartools/tutorials/genome/NC_000962.3.dict\n",
      "16:00:09.772 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/n/home12/pculviner/.conda/envs/mtbvartools/share/gatk4-4.6.1.0-0/gatk-package-4.6.1.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Sun Mar 02 16:00:10 EST 2025] CreateSequenceDictionary --REFERENCE genome/NC_000962.3.fasta --TRUNCATE_NAMES_AT_WHITESPACE true --NUM_SEQUENCES 2147483647 --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false\n",
      "[Sun Mar 02 16:00:11 EST 2025] Executing as pculviner@holy8a26303.rc.fas.harvard.edu on Linux 4.18.0-513.18.1.el8_9.x86_64 amd64; OpenJDK 64-Bit Server VM 17.0.14-internal+0-adhoc..src; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.6.1.0\n",
      "[Sun Mar 02 16:00:11 EST 2025] picard.sam.CreateSequenceDictionary done. Elapsed time: 0.03 minutes.\n",
      "Runtime.totalMemory()=285212672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool returned:\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='gatk CreateSequenceDictionary -R genome/NC_000962.3.fasta', returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\n",
    "    'bwa index genome/NC_000962.3.fasta',\n",
    "    shell=True, env=env)\n",
    "subprocess.run(\n",
    "    'gatk CreateSequenceDictionary -R genome/NC_000962.3.fasta',\n",
    "    shell=True, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e71d7c-728e-45c9-8d32-3a92adb062a7",
   "metadata": {},
   "source": [
    "---\n",
    "Load in SRA example accession numbers - the first strain, SRR10522783, is a canettii sample which is a common MTBC outgroup. Including an outgroup enables rooting of the tree.\n",
    "\n",
    "For your own trees, canettii could also be a good choice for outgroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a02599-6060-46ab-9b01-a7afacf597c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SRR10522783' 'ERR2679299' 'ERR2446424' 'ERR2446415' 'ERR551110'\n",
      " 'SRR7496532' 'SRR6397656' 'DRR185092' 'ERR3256257' 'ERR11044579'\n",
      " 'SRR7496478' 'SRR6797503' 'SRR6930928' 'SRR2101286' 'SRR8217901'\n",
      " 'SRR6046329' 'SRR6480571' 'SRR5266537' 'SRR5153716' 'ERR11068733'\n",
      " 'DRR130114' 'SRR6807685' 'SRR8651614' 'SRR6856120' 'SRR8439315'\n",
      " 'ERR3273187' 'ERR137210' 'DRR185016' 'SRR6152938' 'SRR6397378'\n",
      " 'DRR185093' 'ERR2446119' 'ERR11067324' 'SRR2100524' 'ERR3275540'\n",
      " 'ERR11051007' 'ERR11068227' 'ERR11044288' 'ERR11044351' 'SRR6964596'\n",
      " 'ERR11068958' 'ERR2446390' 'SRR2100329' 'ERR11067544' 'ERR2514624'\n",
      " 'ERR2513490' 'ERR1873433' 'ERR11049166' 'SRR6074074' 'ERR551391'\n",
      " 'SRR6397635' 'ERR3275899' 'ERR11081805' 'SRR11033762' 'ERR3287431'\n",
      " 'ERR11081108' 'ERR400371' 'ERR11042993' 'ERR11082629' 'ERR2514855'\n",
      " 'ERR2446408'] 61\n"
     ]
    }
   ],
   "source": [
    "strain_list = pd.read_csv('tree_strains.txt').sra.values\n",
    "print(strain_list, len(strain_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2705b5e-6443-464d-956c-b8dfb9a6f6a9",
   "metadata": {},
   "source": [
    "## Parallel Run of Variant Calling Using SLURM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd211ab-3b4b-458c-941a-8b2574e36389",
   "metadata": {},
   "source": [
    "Run all above numbers, spawning workers. Can also run sequentially or using local parallelism. The pipeline can also be run on local fastq files by using the `--fastq-path` (give a single path for SE or a comma separated path for PE) option instead of the `--sra` option.\n",
    "\n",
    "Fastq downsampling is critical to improve pipeline throughput as many bacterial samples from the SRA are massively over-sequenced. For trial run, a target depth of 30 is adequate, but for high quality trees, better to target ~100. There are diminishing returns above 100 and the breseq variant caller (the most computationally expensive step) begins to take a lot more time. Setting target depth to 0 will not downsample and use all reads. See `sra_variant_pipelinepy --help` for additional pre-filtering options (minimum depth, ignore lineages, minimum alignment) that cam be tweaked from defaults to avoid wasted commpute time on low-quality samples.\n",
    "\n",
    "Logs for each sample will be stored in the `logs` directory. A frequent failure point for samples is SRA server instability - you might see error messages associated with `prefetch` if this is the case. The script will attempt to download each sample 3 times before giving up.\n",
    "\n",
    "Results from each step are stored in the output folder corresponding to each sample in the output (`pipeline_results`) directory. For debugging, `--keep-intermediates` can be used, but for large numbers of samples this can use massive amounts of space as many intermediate files are not compressed to decrease resource use. If higher speed node storage is avalible on `tmp`, `--tmp-path` can be set to `/tmp/` and this will be used for temporary files. Note that a lot of disk I/O will still happen even off of `tmp` so if a path to a fast short term scratch disk is availible, ideally files should be output there and then results can be moved to cold storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e368bde4-1180-4464-8983-8839a1f480db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-02 16:00:34 - Launching SLURMCluster client (25 workers x 2 CPU x 8GB x 4:00:00 @ sapphire with 1 workers / node)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [1:11:50<00:00, 70.67s/it]   \n",
      "2025-03-02 17:12:31,983 - distributed.batched - INFO - Batched Comm Closed <TCP (closed)  local=tcp://10.31.147.62:34921 remote=tcp://10.31.147.62:35600>\n",
      "Traceback (most recent call last):\n",
      "  File \"/n/home12/pculviner/.conda/envs/mtbvartools/lib/python3.12/site-packages/distributed/batched.py\", line 115, in _background_send\n",
      "    nbytes = yield coro\n",
      "             ^^^^^^^^^^\n",
      "  File \"/n/home12/pculviner/.conda/envs/mtbvartools/lib/python3.12/site-packages/tornado/gen.py\", line 766, in run\n",
      "    value = future.result()\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"/n/home12/pculviner/.conda/envs/mtbvartools/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 263, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n"
     ]
    }
   ],
   "source": [
    "client = startClient(\n",
    "    n_workers=25,  # spawn 25 workers using SLURM - workers will accept new tasks as others complete\n",
    "    use_local=False,  # can also do this on a single local process, but be sure not to spawn more workers than cores or local memory allows\n",
    "    use_slurm=True,  # using SLRUM - below are SLRUM specific options\n",
    "    log_dir='logs',  # outputs worker logs and below, logs per sample\n",
    "    queue='sapphire',  # name of our queue, this will NOT be the same for all queues\n",
    "    process_per_node=1,  # each worker will run separately, not multiple per node\n",
    "    cores_per_process=2,  # SLURM processors to provide to process\n",
    "    memory_per_process='8GB',  # SLURM memory to allocate per process\n",
    "    walltime='4:00:00')  # maximum walltime before worker cancels\n",
    "\n",
    "common_args = '\\\n",
    "--dir pipeline_results \\\n",
    "--threads 2 \\\n",
    "--tmp-path FALSE \\\n",
    "--genbank genome/NC_000962.3.gb \\\n",
    "--fasta genome/NC_000962.3.fasta \\\n",
    "--allowed-lineages any \\\n",
    "--target-depth 30'\n",
    "\n",
    "futures = []\n",
    "for sra in strain_list:\n",
    "    futures.append(client.submit(\n",
    "        subprocess.run, f'sra_variant_pipeline.py --sra {sra} --output {sra} {common_args} > logs/{sra}.out', shell=True, env=env))\n",
    "\n",
    "outputs_list = []\n",
    "for f in tqdm(futures):\n",
    "    outputs_list.append(client.gather(f))\n",
    "    f.release()\n",
    "\n",
    "client.shutdown()  # this shuts down workers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47c76b1-40d3-409e-bc61-108ed217db03",
   "metadata": {},
   "source": [
    "Collect results into a single csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15a6d1e5-5dc0-4b0b-8c2d-30b7e7bee227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectResults(target_directory, name_list):\n",
    "    completed_list = []\n",
    "    error_list = []\n",
    "    unhandled_list = []\n",
    "    completed = 0\n",
    "    caught_error = 0\n",
    "    unhandled_error = 0\n",
    "    for name in tqdm(name_list):\n",
    "        try:  # get completed timings\n",
    "            completed_list.append(\n",
    "                pd.read_csv(f'{target_directory}/{name}/results/{name}.results.csv', index_col=0).loc[name])\n",
    "            completed += 1\n",
    "        except FileNotFoundError:\n",
    "            try:\n",
    "                error_list.append(\n",
    "                    pd.read_csv(f'{target_directory}/{name}/results/{name}.error.results.csv', index_col=0).loc[name])\n",
    "                caught_error += 1\n",
    "            except FileNotFoundError:\n",
    "                unhandled_error += 1\n",
    "                unhandled_list.append(name)\n",
    "    completed_results = pd.concat(\n",
    "        completed_list, axis=1).T\n",
    "    try:\n",
    "        error_results = pd.concat(\n",
    "            error_list, axis=1).T\n",
    "    except:\n",
    "        error_results = None\n",
    "    print(f'{completed} completed, {caught_error} caught errors, {unhandled_error} unhandled errors.')\n",
    "    return completed_results, error_results, unhandled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e606da25-e903-4845-bf7d-ed1b1cc874d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:02<00:00, 22.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 completed, 0 caught errors, 0 unhandled errors.\n"
     ]
    }
   ],
   "source": [
    "results_df, _, _ = collectResults('pipeline_results', strain_list)\n",
    "results_df.to_csv('variant_calling_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cabc84b-7f05-4590-8cfd-c92262dc2236",
   "metadata": {},
   "source": [
    "## Prepare a SNP fasta file for tree building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482bf5a1-8b69-495a-9a09-a2501f6b70f2",
   "metadata": {},
   "source": [
    "Assuming all variant calling results appear to be of high quality, prepare an input datasheet for tree fasta generation.\n",
    "\n",
    "Common sample failure modes are low depth (see `mindepth`), low coverage (see `coverage`), failure of TBProfiler to call a lineage (see `call`, note canettii is not called - this is expected behavior), mixed samples (see below), or poor breseq-mutect consensus (see below).\n",
    "\n",
    "The pipeline runs a `TBProfiler` followed by a script to identify conflicting lineage calls which can be caused by mixed infections or contamination. If multiple lineage calls are made it will appear in `conflict_lineages`. The number of SNPs calling each conflicting lineage are denoted in `conflict_snps` - note that sometimes a single SNP will cause a conflicting call - this is may not a \"real\" mixed sample just a lineage arising SNP that arose de novo.\n",
    "\n",
    "The variant script runs GATK's `mutect2` and `breseq` in consensus mode. SNPs called by `mutect2` are categorized into fixed (AF = 1), near fixed (AF > .9), mixed (.9 > AF > .1), or low alt (AF < .1). A high ratio of mixed to fixed + near fixed can be an indicator of mixed samples or poor quality sequencing. Finally, comparison of the Breseq SNP counts to Mutect2 SNP counts can be used to filter samples - if these values strongly disagree, it might be difficult to call variants with a high certainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "510141f2-4c56-44cf-9267-6e2c9ee5f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_inputs = pd.read_csv('variant_calling_results.csv', index_col=0)\n",
    "\n",
    "datasheet_data = []\n",
    "for index, rdata in results_inputs.iterrows():\n",
    "    row_data = [\n",
    "        index,\n",
    "        f'{index}/results/{index}.breseq.vcf',\n",
    "        f'{index}/results/{index}.miss.breseq.zarr']\n",
    "    datasheet_data.append(row_data)\n",
    "\n",
    "merge_df = pd.DataFrame(\n",
    "    data=datasheet_data,\n",
    "    columns=['label', 'vcf_path', 'miss_path'])\n",
    "\n",
    "# run on all strains\n",
    "merge_df.to_csv(f'tree_fasta_inputs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b499dfc1-88bd-49c8-873a-2cc447bdf58a",
   "metadata": {},
   "source": [
    "Run a batch command to generate fasta files. The script generates a pseudo-genome alignment of all locations with a SNP in at least one sample.\n",
    "\n",
    "The above for loop stores the breseq VCF file as well as an array of breseq \"miss\" locations - places where breseq decided data was too low quality to make a call. To avoid reference bias (where poor quality sequencing results default to looking like the reference, in our case a L4.9 strain, H37Rv), the fasta generation script masks low quality sites from a given sample and fully removes SNPs in regions that were called as poor quality in a fraction of samples (see `--miss-threshold`). As an added step to remove biases, we use a mapping quality filter that was previously calculated (https://pubmed.ncbi.nlm.nih.gov/35020793/, see `--mask`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "203ec4a9-bc4d-4dd2-b1b5-747518e0a0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 5285859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='    sbatch -c 10 -p sapphire -t 2:00:00 --mem=20G -o tree_output/fasta-%j.out --wrap=\"    export PATH=/n/home12/pculviner/.conda/envs/mtbvartools/bin:/n/home12/pculviner/.conda/envs/jlab/bin:/n/sw/Mambaforge-22.11.1-4/condabin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin:/n/home12/pculviner/.local/bin:/n/home12/pculviner/bin:/n/boslfs02/LABS/sfortune_lab/Lab/culviner/bin:/n/boslfs02/LABS/sfortune_lab/Lab/culviner/notebooks/250301_prepare_uploads/mtbvartools/scripts &&     write_snp_fastas.py     --input-csv tree_fasta_inputs.csv     --input-fasta genome/NC_000962.3.fasta     --inputs-dir pipeline_results     --out-dir tree_output     --output snp_fasta     --mask rlc_plus_lowmap_marin.bed     --miss-threshold 0.1     --local-threads 10\"', returncode=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threads = 10\n",
    "path = env['PATH']\n",
    "work_dir = 'tree_output'\n",
    "\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "cmd = f'\\\n",
    "    sbatch -c {threads} -p sapphire -t 2:00:00 --mem=20G -o {work_dir}/fasta-%j.out --wrap=\"\\\n",
    "    export PATH={path} && \\\n",
    "    write_snp_fastas.py \\\n",
    "    --input-csv tree_fasta_inputs.csv \\\n",
    "    --input-fasta genome/NC_000962.3.fasta \\\n",
    "    --inputs-dir pipeline_results \\\n",
    "    --out-dir {work_dir} \\\n",
    "    --output snp_fasta \\\n",
    "    --mask rlc_plus_lowmap_marin.bed \\\n",
    "    --miss-threshold 0.1 \\\n",
    "    --local-threads {threads}\"'\n",
    "subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917aa69-6a3e-43fa-85fa-4eaad0d44c06",
   "metadata": {},
   "source": [
    "Fasta generation outputs show the number of invariant A,T,G,C for input into ascertainment bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e0e3a19-8aa8-4d52-8664-e9e16b5bdb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snp_fasta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_samples</th>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genome_len</th>\n",
       "      <td>4411532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miss_threshold</th>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pass_miss_threshold_sites</th>\n",
       "      <td>4162647.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant_sites</th>\n",
       "      <td>34091.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_variant_strains_to_consider</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>considered_variant_sites</th>\n",
       "      <td>34091.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bed_mask_sites</th>\n",
       "      <td>276750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passing_variant_sites</th>\n",
       "      <td>31027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passing_output_sites</th>\n",
       "      <td>31027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passing_invariant_sites</th>\n",
       "      <td>4025410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invariant_A</th>\n",
       "      <td>699061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invariant_T</th>\n",
       "      <td>699337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invariant_G</th>\n",
       "      <td>1311900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invariant_C</th>\n",
       "      <td>1315112.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     snp_fasta\n",
       "n_samples                                 61.0\n",
       "genome_len                           4411532.0\n",
       "miss_threshold                             0.1\n",
       "pass_miss_threshold_sites            4162647.0\n",
       "variant_sites                          34091.0\n",
       "minimum_variant_strains_to_consider        1.0\n",
       "considered_variant_sites               34091.0\n",
       "bed_mask_sites                        276750.0\n",
       "passing_variant_sites                  31027.0\n",
       "passing_output_sites                   31027.0\n",
       "passing_invariant_sites              4025410.0\n",
       "invariant_A                           699061.0\n",
       "invariant_T                           699337.0\n",
       "invariant_G                          1311900.0\n",
       "invariant_C                          1315112.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('tree_output/snp_fasta.results.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca28d7-a78d-45c1-94a2-325a0f7c07a0",
   "metadata": {},
   "source": [
    "## Tree building with IQTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c5950b-f8a7-43f0-bc6f-efa6a1afda5e",
   "metadata": {},
   "source": [
    "Due to clonal inheritance and mimimal genomic diversity most sites in the Mtb genome are invariant. To generate proper branch lengths, we provide IQTree with the number of constant sites output by the fasta generation script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25971ac4-1487-420d-a56f-afcb366143b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 5285891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='    sbatch -c 20 -p sapphire -t 4:00:00 --mem=30G -o tree_output/tree-%j.out --wrap=\"    export PATH=/n/home12/pculviner/.conda/envs/mtbvartools/bin:/n/home12/pculviner/.conda/envs/jlab/bin:/n/sw/Mambaforge-22.11.1-4/condabin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin:/n/home12/pculviner/.local/bin:/n/home12/pculviner/bin:/n/boslfs02/LABS/sfortune_lab/Lab/culviner/bin:/n/boslfs02/LABS/sfortune_lab/Lab/culviner/notebooks/250301_prepare_uploads/mtbvartools/scripts && export OMP_NUM_THREADS=20 &&     module load Mambaforge/22.11.1-fasrc01 && conda activate mtb_isolates &&     iqtree -T 20 -fconst 699061,1315112,1311900,699337 -s tree_output/snp_fasta.fasta --model GTR -bb 1000 --prefix tree_output/iqtree\"', returncode=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ascertainment bias ordered: A, C, G, T\n",
    "fconst = '699061,1315112,1311900,699337'\n",
    "threads = 20\n",
    "memory = 30\n",
    "work_dir = 'tree_output'\n",
    "input_fasta = f'{work_dir}/snp_fasta.fasta'\n",
    "path = env['PATH']\n",
    "\n",
    "cmd = f'\\\n",
    "    sbatch -c {threads} -p sapphire -t 4:00:00 --mem={memory}G -o {work_dir}/tree-%j.out --wrap=\"\\\n",
    "    export PATH={path} && export OMP_NUM_THREADS={threads} && \\\n",
    "    module load Mambaforge/22.11.1-fasrc01 && conda activate mtb_isolates && \\\n",
    "    iqtree -T {threads} -fconst {fconst} -s {input_fasta} --model GTR -bb 1000 --prefix {work_dir}/iqtree\"'\n",
    "subprocess.run(\n",
    "    cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d0bc5-bd1f-4a2d-b745-a5d60212fedb",
   "metadata": {},
   "source": [
    "Canettii outgroup (SRR10522783) is extremely divergent relative to MTBC. To enable easy plotting in software like itol (https://itol.embl.de/), we root at canettii's parent node and prune out canettii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7def2dcf-18ff-46fe-a177-085ad1c0541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outgroup = 'SRR10522783'\n",
    "work_dir = 'tree_output'\n",
    "tree_label = 'iqtree'\n",
    "\n",
    "# load the tree\n",
    "tree = dendropy.Tree.get_from_path(\n",
    "    f'{work_dir}/{tree_label}.contree', 'newick')\n",
    "# root at outgroup\n",
    "tree.reroot_at_node(\n",
    "    tree.find_node_with_taxon_label(outgroup).parent_node)\n",
    "# ladderize\n",
    "tree.ladderize()\n",
    "tree.write(\n",
    "    path=f'{work_dir}/{tree_label}.rooted.nwk',\n",
    "    schema='newick')\n",
    "tree.prune_taxa_with_labels([outgroup])\n",
    "tree.write(\n",
    "    path=f'{work_dir}/{tree_label}.pruned.nwk',\n",
    "    schema='newick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ee3d9f-f7ce-4d48-82eb-b57cd8c1b31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtbvartools",
   "language": "python",
   "name": "mtbvartools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
